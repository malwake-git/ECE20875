So now we have the formula for calculating the total throughput, the aggregate throughput as well as the per-station throughput if we divided by the number of stations for CSMA. Before doing any calculations we have to specify the DCF protocol parameters L, B, Wmin, and the timeslot lengths Tb, Ts, and Tc that we discussed earlier.

So first, let's assume that we're going to use the DCF that's being used in 802.11g at 54 megabits per second, at the 54 Mbps maximum transmission speed that that protocol offers. From the protocol specifications, the relevant timing parameters are we have a slot time of 9 microseconds, and we'll see where the slot time fits in in a second, the SIFS period is 10 microseconds, the DIFS period is actually defined in terms of SIFS it's SIFS + 2 times the slot time and if we do that out it turns out to be 28 microseconds. And also Wmin the minimum window size is 15, the minimum value that we would randomly select based upon for the backoff counter is 15.

And there's other parameters that we also need to compute tau, and remember tau is the probability of a station transmitting that we found the formula for before. We need L, which is the payload length, that we will assume to be 8192 bits, it's just several different permutations and combinations of bits, and B we're going to assume is 3. So the maximum number of backoff counters we can go through is 3. We'll assume those are the default values and later we'll sweep some of these values and here including these parameters as well as the window parameters above to see their impact on the total throughput.

So from this we then need to come up with the duration of the different timeslots, Tb Ts and Tc. Tb is the duration of a backoff, simply the length of a DIFS period, so Tb is 28 microseconds which is just equal to DIFS. The duration of Ts, now this is going to get a bit more complicated to compute, a successful transmission consists of transmission of both a data frame from the sender and an ACK frame from a receiver together with the appropriate spacing. So a successful transmission has a data frame + a SIFS period + an ACK frame + DIFS. So we already know what DIFS and SIFS are from before for 802.11g, so now we have to assume exactly how long the data frame transmission is going to take and how long the ACK frame transmission is going to take.

So the data frame we can break that up further into a couple different parts. It consists of a 16 microsecond physical layer preamble, so the PHY layer preamble is one aspect of it and that's 16 microseconds. There's a 40 bit PHY header, so a physical layer header, this is 40 bits. A 240 bit MAC header. And you don't have to worry per se about what the PHY layer versus the MAC layer is or what the PHY header versus the MAC header is for that matter, just know that each of the layers in the protocol stack for the Internet is going to add a different layer on to the messages that are being transmitted over the Internet so they can be properly decoded at the receiver and at the appropriate elements in the Internet.

Here we are just simply concerned with figuring out how long all these things are so we can come up with an expression for the total time its going to take to transmit the data frame. Then after the MAC header, it also has the L-bit payload so there's the L bit payload and remember the payload is actually what we're trying to send, it's the actual message that's being sent and the rest of that around this is to make sure its sent successfully and when it doesn't get there successfully to know what to do with that. And also it has a 32-bit CRC code. So there's the PHY layer preamble, the PHY layer header, the MAC layer header, the L-bit payload, and the CRC code that all makes up the data frame.

So the protocol specifications state that the PHY layer header is going to be further split and sent at different rates: the first 24 bits is sent at 6 megabits per second, to be more robust to channel errors at a lower rate, and the remaining 16 bits is send at 54 Mbps and then that 24 + 16 is going to give us the total length of the PHY layer header. So the time that it takes to send the full data frame is in microseconds 16 microseconds for the PHY layer preamble plus then we take the header the first 24 bits are sent at 6 megabits per second so 24 divided by 6 is going to give us in microseconds the amount of time that is going to take to send and then everything else after this is going to be sent at 54 Mbps, so we have the remaining 16 bits of the header, the MAC header which is also sent another 240 bits, and we have the 32 bit CRC code which is all sent at the same transmission speed 54 Mbps, and additionally we have let's not forget the actual payload which is sent at 54 Mbps. And we're dividing by the speed because if we have the length in bits at the top and the speed at the bottom this is going to give us the amount of time it takes to send this.

So if we simplify this out and do the math accordingly we get 25.33 plus L divided by 54 microseconds. And that's for the data frame so far. And then we also have to do the same thing for the acknowledgment frame we're going to send. So this 25.33 plus L over 54 is for the data frame, and now we have to find for the acknowledgment frame. The acknowledgment frame is a bit simpler, it has a 16 microsecond PHY layer preamble and that's again 16 microseconds, it has a 40 bit PHY header again they are going to be split and sent at different rates as we had before, and 112 bit MAC layer frame that consists of a header and a CRC, so we have an additional MAC layer frame this is 112 bits. So this down here, this computation before that is for the data frame, and this one up here is for the ACK frame. So then when we do this out, and we add, we don't have a payload in this, so we don't have to get anything in terms of L we just have to add up the relevant quantities, it's 16 + 24 over 6 + the rest is sent at 54 megabits per second 16 + 112 over 54 equals 22.37 microseconds. So this right here, this calculation and this breakdown is for the ACK frame portion of this.

So now, to find Ts in total, we have to add everything together. We start with this 25.33 plus L over 54, the data frame, we have to add in the time of the SIFS which is 10, we have to add in the time it takes for the ACK, which is 22.37, and then we have to add in the time for the DIFS which is 28. And all in all, that comes out to be 25.70 + L over 54 microseconds. And again, Ts is equal to Tc which we said before. The time it takes to detect a collision is the time it takes for a successful transmission to pass.

So with these values, we first solve numerically for tau. And remember that formula from before, we had tau equals 1 over 1 + 1 - c over 1 - c to the B + 1 sum from i = 0 to B ci 2 to the i - 1 Wmin where c remember is equal to 1 - 1 - tau to the N - 1. So we plug in this value for c here, we have tau, and then we can solve numerically for tau just by figuring out which value of tau will make both sides of the equation equal to one another.

Then we put the solution for tau into this formula for the throughput which we had before. And I'm going to expand this formula now and not write it in terms of Pt and Ps anymore, instead in terms of tau and N. So this is going to be N tau times 1 - tau to the N - 1 L that's giving us the number of bits in a successful transmission, and then at the bottom we have 1 - tau N times Tb if it's a backoff we have then 1 - 1 - tau to the N - N tau 1 - tau to the N - 1 Tc to give us a collision slot, and then we have N tau times 1 - tau to the N - 1 Ts if it's a successful transmission slot.

So, if we have 5 stations, a maximum backoff stage of 3, a minimum window size of 15, and a payload of 8,192, tau the value of tau is going to come out to be 0.0765, or about 7.65 percent of a time that a station is going to be transmitting. And with that value of tau we can then plug that into the total throughput formula again, with tau for different values of N, and figure out what the effect of the number of stations is going to be. And we can also sweep any one of these parameters we want as well.

So what is the impact of the number of stations and the medium access aggressiveness? These are just two of the parameters we could sweep.

The reason we are going to look at the impact of the number of stations is because this is the key result we have been looking at all along to quantify how well WiFi is able to scale to a large number of devices. And so this graph on the left hand side shows that as we vary the value of N what happens to the throughput, it shows the aggregate throughput which is this plot here and also the per-station throughput which is always decreasing as it should be, because everyone is always going to be getting a smaller piece of the pie as we add more stations in.

Again this is the key graph we have been working for, it quantifies the impact of the crowd size on WiFi's throughput. So as N increases we see for the per-station throughput that it is always decreasing, because more stations are competing for the same channel. The drop is quite sharp from N equals 2 through N equals 15, and the throughput becomes quite low, actually even below 2 Megabits per second once N becomes 10, and obviously once N becomes 15 then we are much below 2 megabits per second. This highlights the inscalability of CSMA, the fact that once we hit 10 stations, everyone is going to be getting 2 Mbps or lower, which is if the total channel supports 54 Mbps that is just a small fraction of what the total channel could provide. As for the aggregate throughput that initially increases for small values of N, which is a bit different from Aloha before if you remember that the aggregate throughout was always decreasing. At least with CSMA as we start to add the first few stations we are actually going to see some increase in the throughput. The aggregate throughput initially increases because the stations are fundamentally limited by their exponential backoff mechanism. Even when a station has no competitors for the channel it is still going to pick a transmit slot uniformly at random between 0 and Wmin, so its still going to be going through some sort of wait and listen period, and that's going to lead to inefficiency, so as we do have more stations it's going to help utilizing the channel more, up until we get to about N = 5 at which point the contention kicks in.

Overall, despite the advertised throughout of 65 Mbps of 802.11g, the actual maximum throughput we achieve here is just about 25 Mbps, and that's less than 50 percent regardless of the number of stations we have. This is in part because only the payload is sending at 54 megabits per second, and there's also significant overhead. So recall that the maximum throughput for Aloha was monotonically decreasing with the number of stations. Through implicit message passing, and through carrier sensing, CSMA is able to obtain a high throughput for very small numbers of users, but still drops as the number of users gets larger. This is the price we pay for having no further explicit coordination. A centralized scheduler, the PCF as opposed to the DCF, would have incurred even more coordination overhead, and would have in turn provided the best performance, but in many networks it is infeasible to afford such a centralized scheduler especially as people are coming and going constantly and it becomes very difficult to be able to coordinate that in real time.

We can also vary Wmin or the minimum window size to see what happens. A smaller Wmin means that the stations have higher aggressiveness in using the channel, because the amount they are going to back off is generally going to be smaller because they are going to be choosing random numbers in smaller ranges. And this plot here shows the effect as Wmin increases, and therefore become less aggressive or more conservative in the use of the channel for different values of N, N equals 5, N equals 10, and N equals 20. So when the channel is not congested say when N equals 5, which as we saw before in the prior graph is really a state where we don't have too much congestion yet, it actually helps to be more aggressive, so as we're more aggressive and we drop Wmin, we've going to increase the aggregate throughput to extent until we hit a point, and beyond that it becomes too aggressive.

The channel becomes congested say when we have 20 people, being aggressive is actually going to always lead to more collisions, so it's better to choose a larger Wmin and be less aggressive, we want a Wmin that's much higher because you can see here increasing Wmin when N is 20 is only going to help us increase the total throughput. And if we choose really small values of Wmin we're just going have collisions almost constantly and therefore we're going to be starved to near zero throughput or very low throughput for each of the devices. So in this case it helps to be less aggressive, so a less congested channel helps to be more aggressive and a more congested channel it helps to be less aggressive, varying N and varying Wmin, we can also vary the payload L, we can also vary B the maximum number of backoffs, but the key takeaway here is that CSMA fixes some of the problems that we saw by Aloha through all of its properties of distributed coordination, and some message passing, and some prioritization, and some binary exponential backoff and carrier sensing and all those other properties that are in there. It makes it a very simple protocol to run, especially in the unlicensed frequency bands that are used in WiFi. But still, it fixes some of those problems but it is not scalable to a large number of devices. The per-station throughput drops very low, very quickly and quite rapidly by about 10 stations, and we're getting only about 1 over 25 of what the channel could be providing, and that's not very high. So it's no wonder then that when you're at a hotspot you tend to see much lower performance then you would when you're at home and you dont have a lot of people around.